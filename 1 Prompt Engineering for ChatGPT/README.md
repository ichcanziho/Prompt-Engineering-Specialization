# Prompt Engineering for ChatGPT

## INDEX 0

- [Course Introduction](#course-introduction)
- [Large Language Model Basics](#large-language-model-basics)
- [What are Prompts?](#what-are-prompts)
- [Intro to Prompt Patterns](#intro-to-prompt-patterns)
- [Prompts, Conversations, and New Information](#prompts-conversations-and-new-information)
- [Introduction to Prompt Patterns](#introduction-to-prompt-patterns)
- [Effective Prompts](#effective-prompts)
- [Prompt Patterns Catalog 1](#prompt-patterns-catalog-1)
- [Prompt Patterns Catalog 2](#prompt-patterns-catalog-2)

## Course Introduction
[<- Return to INDEX 0](#index-0)

### INDEX 1

- [Motivation Example: Building a Meal Plan with a Fusion of Food from Ethiopia and Uzbekistan that is keto](#motivation-example-building-a-meal-plan-with-a-fusion-of-food-from-ethiopia-and-uzbekistan-that-is-keto)
- [Overview of the Course](#overview-of-the-course)
- [Motivating Example: Act as a Speech Pathologist](#motivating-example-act-as-a-speech-pathologist)
- [Setting Up an Account and Using ChatGPT](#setting-up-an-account-and-using-chatgpt)

### Motivation Example: Building a Meal Plan with a Fusion of Food from Ethiopia and Uzbekistan that is keto
[<- Return to INDEX 1](#index-1)


![img.png](ims%2FC1%2Fimg.png)

![img_2.png](ims%2FC1%2Fimg_2.png)


El video proporciona una visión exhaustiva sobre cómo utilizar ChatGPT y otros modelos lingüísticos potentes como herramientas 
para materializar ideas innovadoras, más allá de las aplicaciones convencionales de escritura de textos o respuestas a preguntas. 

![img_4.png](ims%2FC1%2Fimg_4.png)

A través de un ejemplo personal, el ponente ilustra cómo ChatGPT puede asistir en la creación de un plan de comidas único, 
combinando las cocinas de Uzbekistán y Etiopía en una dieta cetogénica limitada a 2000 calorías diarias, con ingredientes 
accesibles en el mercado estadounidense. 

Este reto, presentado como altamente complejo para cualquier persona, fue abordado eficazmente por ChatGPT, demostrando 
su capacidad para ofrecer soluciones detalladas e innovadoras.

![img_5.png](ims%2FC1%2Fimg_5.png)

![img_6.png](ims%2FC1%2Fimg_6.png)

Además de diseñar un plan de comidas, el video describe cómo ChatGPT se utilizó para generar historias de batalla inspiradas en Pokémon, con el objetivo de motivar a un niño de nueve años a probar nuevos platos. Este enfoque creativo pone de manifiesto la flexibilidad y la capacidad de adaptación de ChatGPT a contextos familiares y de entretenimiento.

![img_7.png](ims%2FC1%2Fimg_7.png) 

![img_8.png](ims%2FC1%2Fimg_8.png)

![img_9.png](ims%2FC1%2Fimg_9.png)

La exploración continúa con la incorporación de un juego educativo sobre matemáticas y nutrición, también diseñado por ChatGPT, para interactuar de manera divertida y educativa durante la cena. El ponente menciona cómo se avanzó aún más en la idea, utilizando sus conocimientos informáticos para desarrollar software basado en las actividades propuestas, lo cual subraya el potencial sin explotar de los modelos lingüísticos en la generación de código y el desarrollo de aplicaciones.

![img_10.png](ims%2FC1%2Fimg_10.png)

Chat GPT permite generar código python de manera simple y eficaz que permite bocetear rápidamente una idea y transformarla en
un proyecto de software. En este caso se creo un pequeño juego web con base en la idea del juego de fracciones inspiradas en Pokémon.

![img_11.png](ims%2FC1%2Fimg_11.png)

En resumen, el video destaca el poder de ChatGPT como una herramienta multifacética que, al ser correctamente empleada, puede transformar ideas complejas y abstractas en realidades tangibles y funcionales, como planes de comidas personalizados, actividades educativas lúdicas y desarrollo de software, superando con creces las expectativas convencionales sobre sus capacidades. Esta narrativa no solo demuestra la versatilidad de ChatGPT, sino que también inspira a los espectadores a explorar y experimentar con estas tecnologías para lograr resultados innovadores en diversos campos de interés.

### Overview of the Course
[<- Return to INDEX 1](#index-1)

**Introducción al Curso y al Instructor:**

![img_12.png](ims%2FC1%2Fimg_12.png)

El curso de ingeniería rápida es impartido por Jules White, quien es profesor asociado de informática en Vanderbilt y decano adjunto de programas de aprendizaje estratégico de la Escuela de Ingeniería de Vanderbilt. El objetivo principal del curso es explorar la interacción con grandes modelos lingüísticos como ChatGPT, resaltando cómo estos pueden ser herramientas para impulsar la creatividad humana y realizar tareas de forma más rápida y eficiente.

**Propósito y Visión del Uso de Grandes Modelos Lingüísticos:**

Jules White tiene la intención de cambiar la percepción de herramientas como ChatGPT, generalmente vinculadas a prácticas negativas como el plagio, y mostrar cómo pueden ser fundamentales para ampliar la creatividad humana, programar, crear arte, mejorar la escritura entre otras aplicaciones. El curso pretende enseñar el uso efectivo de estas herramientas para llevar a cabo tareas creativas y funcionales.

**Requisitos del Curso:**

![img_13.png](ims%2FC1%2Fimg_13.png)

No es necesario tener experiencia en programación para beneficiarse del curso. Sin embargo, es útil estar familiarizado con conceptos básicos de informática, tales como la administración de archivos y el uso de interfaces de línea de comandos. Las habilidades de redacción y pensamiento creativo son importantes para crear indicaciones eficaces para modelos de lenguaje de gran tamaño.

**Importancia de la Escritura y la Creatividad:**

![img_14.png](ims%2FC1%2Fimg_14.png)

La capacidad de escribir de forma clara y eficaz es crucial para trabajar con grandes modelos lingüísticos. La creatividad y la apertura a la exploración también son enfatizadas como elementos esenciales para el uso eficaz de estas herramientas, subrayando la importancia de ser innovadores y flexibles en su aplicación.

**Objetivos del Aprendizaje:**

![img_15.png](ims%2FC1%2Fimg_15.png)

- Entender y utilizar indicaciones para interactuar con modelos de lenguaje de gran tamaño.
- Aprender a crear indicaciones efectivas aprovechando patrones de datos de entrenamiento específicos.
- Utilizar modelos de lenguaje de gran tamaño para diversas tareas como exploración del conocimiento, creación de prototipos, producción de contenido, y evaluación.
- Aprender técnicas para refinar indicaciones y mejorar los resultados.

**Meta del Curso:**

El curso aspira a inspirar a los estudiantes a aplicar los conceptos aprendidos para explorar sus intereses personales, fomentar la creatividad, y facilitar la resolución de problemas complejos. Se pone un énfasis particular en la utilización de grandes modelos lingüísticos para acelerar la concreción de ideas y pensamientos.


### Motivating Example: Act as a Speech Pathologist
[<- Return to INDEX 1](#index-1)


**Ejemplo Práctico de Ingeniería Rápida con ChatGPT: Aprovechamiento de los Modelos Lingüísticos**

![img_16.png](ims%2FC1%2Fimg_16.png)

El curso de ingeniería rápida provee un ejemplo ilustrativo sobre cómo podemos explotar las capacidades de modelos lingüísticos como ChatGPT para resolver problemas complejos mediante el uso de patrones específicos en las instrucciones que les proporcionamos.

**El Patrón de Persona en Acción:**

![img_17.png](ims%2FC1%2Fimg_17.png)

Un enfoque destacado en el curso es el "patrón de persona", una técnica donde se le pide a ChatGPT que asuma el rol de un individuo, profesional, objeto inanimado o animal para abordar un problema desde una perspectiva especializada. Este patrón se demuestra con el escenario de querer entender y analizar el habla de un niño de tres años desde la perspectiva de un fonoaudiólogo, sin tener conocimientos previos en el área.

**Aplicación del Patrón:**

![img_18.png](ims%2FC1%2Fimg_18.png)

El profesor Jules White describe cómo usó ChatGPT, solicitándole que actuara como una fonoaudióloga para evaluar un ejemplo de habla proporcionado por su hijo de tres años. ChatGPT, asumiendo el papel solicitado, generó un informe que identificó potenciales errores fonológicos y de articulación comunes en niños de esa edad, describiendo con precisión las posibles áreas de preocupación y sugerencias sobre cómo entender mejor esos errores.

**Beneficios de la Implementación:**

Este enfoque demuestra cómo se puede acceder a conocimientos especializados sin ser un experto en el campo, simplemente sabiendo cómo pedir ayuda de manera efectiva a los modelos lingüísticos. La simulación de una consulta a un experto por parte de ChatGPT proporcionó un análisis detallado que el profesor no podría haber formulado por sí mismo debido a la falta de conocimiento técnico en patología del habla y lenguaje.

**Reflexiones Finales:**
![img_19.png](ims%2FC1%2Fimg_19.png)
La capacidad de ChatGPT para emular a un profesional y entregar un informe detallado no sólo muestra su versatilidad y potencial para asistir en diversas áreas, sino que también resalta cómo estas herramientas pueden permitirnos concentrarnos más en las tareas que valoramos o disfrutamos, dejando que la inteligencia artificial maneje aspectos más tediosos o fuera de nuestro ámbito de expertise.



### Setting Up an Account and Using ChatGPT
[<- Return to INDEX 1](#index-1)

**Elementos Necesarios:**
![img_20.png](ims%2FC1%2Fimg_20.png)
Para participar efectivamente en el curso de ingeniería rápida, los únicos requisitos son un navegador web, una conexión a Internet, y una cuenta en OpenAI. Esta configuración permite el acceso a ChatGPT, una herramienta central para el aprendizaje y la aplicación de los conceptos del curso.

**Recomendación de Uso de ChatGPT:**

Se sugiere usar ChatGPT por varias razones: los ejemplos del curso han sido probados con este modelo, y su interfaz es amigable para usuarios nuevos. Para comenzar, se debe visitar chat.openai.com y seguir el proceso de registro o inicio de sesión, en caso de ya tener una cuenta.

**Interfaz de ChatGPT:**
![img_21.png](ims%2FC1%2Fimg_21.png)
Una vez dentro, la interfaz se presenta sencilla con un cuadro de mensajes en la parte inferior para interactuar con ChatGPT. Los usuarios pueden seleccionar entre diferentes modelos, aunque se recomienda usar el modelo GPT-3.5 por defecto por su rapidez y accesibilidad.

**Interacción con ChatGPT:**
![img_22.png](ims%2FC1%2Fimg_22.png)
Para interactuar, simplemente se escribe el mensaje o instrucción y se envía. Es importante destacar que la forma en que se redactan las instrucciones puede influir significativamente en la calidad de las respuestas obtenidas, un enfoque clave en el curso.

**Estrategias de Aprendizaje:**
![img_23.png](ims%2FC1%2Fimg_23.png)
Se aconseja iniciar una nueva conversación para cada concepto nuevo o patrón a probar, de manera que las interacciones previas no afecten los resultados de los experimentos. Esta práctica fomenta un enfoque de "borrón y cuenta nueva" para cada nueva lección o concepto introducido en el curso.

**Aplicabilidad del Conocimiento:**

Aprender a comunicarse efectivamente con ChatGPT no solo prepara a los estudiantes para utilizar este modelo específico sino que también les equipa con las habilidades necesarias para interactuar con otros modelos de lenguaje grandes. Este conocimiento es transferible y valioso para la incorporación de instrucciones en programas o el uso en otras herramientas de inteligencia artificial.

**Conclusión:**

La facilidad de acceso y la simplicidad de la interfaz de ChatGPT lo convierten en una herramienta ideal para aprender sobre ingeniería rápida y la interacción con modelos de lenguaje grandes. Al dominar la técnica de redactar instrucciones claras y efectivas, los estudiantes pueden mejorar significativamente la calidad de las respuestas generadas, abriendo así un amplio abanico de posibilidades creativas y técnicas para explorar.

## Large Language Model Basics
[<- Return to INDEX 0](#index-0)

### INDEX 2

- [What are Large Language Models?](#what-are-large-language-models)
- [Randomness in Output](#randomness-in-output)
- [Creating Your First Prompts](#creating-your-first-prompts)

#### What are Large Language Models?
[<- Return to INDEX 2](#index-2)

Los modelos de lenguaje grandes (MLG) son herramientas avanzadas de inteligencia artificial que buscan entender y generar texto humano de manera coherente y relevante. Aquí hay un resumen sobre qué son, cómo funcionan, y algunas peculiaridades a tener en cuenta cuando se usan:

#### ¿Qué son los Modelos de Lenguaje Grandes?

![img.png](ims%2FC2%2Fimg.png)

- Son sistemas de inteligencia artificial diseñados para procesar, entender y generar texto en lenguaje natural.
- Están desarrollados a partir de enormes cantidades de datos textuales recopilados de Internet.

#### ¿Qué hacen?

- Generan texto palabra por palabra basándose en la entrada proporcionada por el usuario.
- Intentan predecir la siguiente palabra en una secuencia de texto dada la entrada, y este proceso se repite hasta completar una respuesta.
- Pueden realizar tareas como completar texto, responder preguntas, redactar ensayos, traducir idiomas y más.

#### ¿Cómo funcionan?

![img_1.png](ims%2FC2%2Fimg_1.png)

- Funcionan basándose en la predicción de la siguiente palabra en una secuencia de texto, tomando en cuenta el contexto proporcionado por las palabras anteriores.
- Utilizan patrones de lenguaje aprendidos a partir de los datos en los que fueron entrenados para generar respuestas coherentes y relevantes.
- La generación de texto continúa hasta que el modelo considera que ha producido una respuesta suficiente, basándose en su entrenamiento.

#### Puntos Clave a Recordar:

![img_2.png](ims%2FC2%2Fimg_2.png)

1. **Predicción de Palabras:** La esencia de su funcionamiento es predecir la siguiente palabra en una secuencia, basándose en el input que reciben.
   
2. **Entrenamiento:** Se entrenan con vastas cantidades de texto de Internet para aprender patrones de lenguaje humano.

3. **Variabilidad:** Estos modelos pueden producir respuestas variadas para una misma entrada debido a la aleatoriedad en su proceso de generación de texto.

4. **Actualización y Datos de Entrenamiento:** Su conocimiento está limitado al momento de su último entrenamiento. Esto significa que los eventos recientes o la información actualizada tras ese período pueden no estar incluidos en su base de conocimiento.

5. **Aplicabilidad:** Aunque son muy avanzados, no son perfectos y sus respuestas pueden contener errores o variaciones. Es importante tener esto en cuenta al usarlos para tareas críticas.

![img.png](img.png)

### Randomness in Output
[<- Return to INDEX 2](#index-2)

La aleatoriedad y la imprevisibilidad inherentes a los modelos de lenguaje grandes (MLG), como ChatGPT, presentan tanto desafíos como oportunidades en el diseño de interacciones eficaces con estas herramientas de inteligencia artificial. Estas características, aunque pueden complicar la obtención de respuestas precisas y repetibles para ciertas consultas, también abren puertas a la creatividad y generación de ideas novedosas. Aquí, exploramos cómo la ingeniería de indicaciones (prompt engineering) ayuda a navegar y aprovechar estas peculiaridades de los MLG.

#### Aleatoriedad y Creatividad

![img_3.png](ims%2FC2%2Fimg_3.png)

Los MLG no garantizan respuestas idénticas ante la misma pregunta debido a su diseño intrínsecamente variable, lo cual puede ser benéfico para tareas que se benefician de la generación de múltiples ideas o soluciones, como la escritura creativa. Sin embargo, esta aleatoriedad puede no ser deseable en contextos donde se buscan respuestas específicas y uniformes.

#### Enfrentando la Imprevisibilidad

![img_4.png](ims%2FC2%2Fimg_4.png)

Parte del desafío al trabajar con MLG implica limitar esta imprevisibilidad sin sofocar la capacidad del modelo para generar respuestas innovadoras. La ingeniería de indicaciones emerge así como una técnica crucial para formular preguntas o comandos de una manera que alinee mejor las respuestas del modelo con nuestras expectativas, tanto en precisión como en creatividad.

#### Ejemplo Práctico

![img_5.png](ims%2FC2%2Fimg_5.png)

El ejemplo de preguntar a ChatGPT cuántos pájaros hay afuera de una casa ilustra bien la variabilidad de las respuestas que puede ofrecer un MLG. A pesar de que el modelo no puede percibir el mundo físico y sus respuestas gravitan en torno a este hecho, las sugerencias concretas que ofrece varían con cada consulta. Estas variaciones son un recordatorio constante de la naturaleza impredecible de los MLG.

#### Estrategias de Ingeniería Rápida

El arte de redactar indicaciones (prompt engineering) involucra el diseño cuidadoso de preguntas y comandos para guiar al MLG hacia respuestas más predecibles, precisas o creativas, dependiendo de la necesidad. Esto puede involucrar la especificación de contextos, la delimitación de parámetros de respuesta, y la anticipación de posibles variaciones en las respuestas para ajustar las indicaciones de forma proactiva.

#### Conclusión

La variabilidad en las respuestas de los modelos de lenguaje grandes subraya la importancia de desarrollar habilidades en ingeniería de indicaciones para optimizar la interacción con estas herramientas. Aunque la aleatoriedad puede presentar desafíos, especialmente cuando se buscan resultados específicos o uniformes, también puede ser una fuente valiosa de inspiración y creatividad. Aceptar y comprender esta naturaleza de los MLG es fundamental para explotar su potencial al máximo, adaptando nuestras estrategias de comunicación para obtener los resultados deseados. La ingeniería rápida se convierte así no solo en una habilidad técnica, sino también en una práctica creativa, permitiéndonos explorar nuevas posibilidades y descubrir soluciones innovadoras con la ayuda de la inteligencia artificial.

### Creating Your First Prompts
[<- Return to INDEX 2](#index-2)

**Question 1**

Create a prompt for a large language model, such as ChatGPT, to describe how large language models work. Ask at least three follow-up questions based on the output. Provide the prompts and outputs from the conversation as the answer.

> >prompt 1:
You are a machine learning and deep learning teacher. Your work is to explain how LLMs work in easy terms.
your first question is: how llms work?
> 
>  > ANS 1:
LLMs, or Large Language Models, are like super-smart robots trained to understand and generate human-like text. Imagine feeding a robot a massive library of books, articles, and internet content. This robot learns from all that information and becomes really good at predicting what words should come next in a sentence.
Now, let's break down how LLMs work into simpler steps:
> >
> > Data Collection: LLMs need a lot of text data to learn from. This includes everything from classic literature to tweets and news articles. The more diverse the data, the better the LLM can understand different styles and topics.
> >
> > Training: Once the robot has all this data, it starts training. This is like going through all those books and learning the rules of language. It figures out patterns in how words are used together and learns the meanings of words.
> >
> > Model Architecture: LLMs use a special type of algorithm called deep learning. Deep learning involves layers of artificial neurons that mimic how our brains work. These layers process the text data in increasingly complex ways, allowing the model to understand language deeply.
> >
> > Fine-Tuning: After the initial training, the LLM might undergo fine-tuning to specialize in certain tasks. For example, it could be trained further on medical texts to become a medical assistant or on legal documents to help with legal research.
> >
> > Generating Text: Once trained, the LLM can generate text based on the patterns it has learned. You can give it a prompt, like the beginning of a sentence, and it will predict and generate the next words. It's like having a really smart writing partner who can help you finish your thoughts or even write entire stories.
> >
> > So, in simple terms, LLMs work by learning from a huge amount of text data, understanding the patterns and rules of language, and then using that knowledge to generate text based on given prompts. They're like language wizards trained on the internet!
> > 
> 
> > prompt 2:
in a few words, tell me how you can avoid bias while training LLM on the internet?
>
> > ans 2:
> > To reduce bias in LLM training on the internet:
> >
> > Diverse Dataset: Include a wide range of sources and perspectives.
Preprocessing: Remove or mitigate biased content before training.
Regular Evaluation: Continuously assess and adjust the model to mitigate bias.
Fairness Metrics: Use metrics to measure and address bias in model outputs.
Ethical Guidelines: Follow ethical guidelines and principles in data selection and model development.
>  
> > prompt 3:
an LLM can be used to train another llm?
> 
> > ans 3:
Yes, an LLM can be used to train another LLM, a process known as "transfer learning" or "fine-tuning."
> >
> > Here's how it works:
> >
> >Pre-trained LLM: You start with a pre-trained LLM that has been trained on a large corpus of text data. This pre-trained LLM has already learned a lot about language and can generate text.
> >
> >Fine-tuning: You then take this pre-trained LLM and further train it on a specific dataset or task. This fine-tuning process allows the LLM to specialize in a particular domain or improve its performance on a specific task.
> >
> >Transfer of Knowledge: By fine-tuning on a new dataset, the LLM learns to adapt its knowledge and language understanding to better suit the new context. It can learn new vocabulary, understand domain-specific nuances, and improve its text generation capabilities for the targeted task.
> >
> >Benefits: Fine-tuning a pre-trained LLM is often faster and requires less data compared to training a new LLM from scratch. It leverages the general language knowledge already present in the pre-trained model and focuses on learning the specific aspects of the new task or domain.
> >
> >So, in short, yes, an LLM can be used to train another LLM through the process of transfer learning or fine-tuning.
> 
> >prompt 4:
an LLM could replace the job of an engineer?
>
> >ans 4:
> >While Large Language Models (LLMs) have advanced capabilities in understanding and generating human-like text, they cannot fully replace the job of an engineer. Here are several reasons why:
> >
> >Specialized Skills: Engineers possess specialized skills and knowledge in areas such as mathematics, physics, computer science, and problem-solving. These skills are essential for designing, building, and maintaining complex systems, structures, and technologies.
> >
> >Creativity and Innovation: Engineering often involves creativity and innovation in solving complex problems and designing novel solutions. While LLMs can assist in generating ideas and providing insights, they lack the ability to independently innovate or creatively solve engineering challenges.
> >
> >Hands-On Work: Many engineering tasks require physical interaction, experimentation, and hands-on work, which LLMs cannot perform. Engineers may need to prototype, test, and iterate designs in real-world environments, which involves practical skills beyond text-based analysis.
> >
> >Domain Expertise: Engineers typically specialize in specific fields such as mechanical, electrical, civil, or software engineering. They develop deep domain expertise over years of study and experience, which enables them to tackle complex engineering problems effectively.
> >
> >Safety and Reliability: Engineering projects often involve considerations of safety, reliability, and regulatory compliance. Engineers must ensure that their designs meet industry standards, adhere to safety protocols, and minimize risks, which requires human judgment and expertise.
> >
> >While LLMs can be valuable tools in assisting engineers with tasks such as documentation, data analysis, and simulation, they are unlikely to replace the diverse skill set and expertise of engineers in the foreseeable future. Instead, they are more likely to complement and augment the work of engineers by providing assistance in certain areas.
> >

Create a prompt for a large language model, such as ChatGPT, that asks it to perform an instruction other than answering a question. For example, ask ChatGPT to create a meal plan, plan a trip, create a recipe, or help you diagnose a problem. Provide the prompts and outputs from the conversation as the answer.

> >Prompt 1: User
You're a data scientist teacher, have a vast domain in deep learning, and have a variety of experience in the field. Your job is to create a path to learn from zero to expert for someone who is already a programmer but wants to be a data scientist specialist. You also need to provide information about courses not only related to deep learning but also to soft skills.
>
> >Ans 1:
> >
> >Sure! Here's a comprehensive learning path for someone transitioning from a programmer to a data scientist specialist:
> >
> >Phase 1: Foundation in Data Science and Python
Introduction to Python Programming
> >
> >Resources: Codecademy's Python course, Python.org's official tutorial.
Data Manipulation and Analysis with Python
> >
> >Resources: DataCamp's Python for Data Science course, Pandas documentation and tutorials.
Statistics and Probability
> >
> >Resources: Khan Academy's Statistics and Probability courses, Coursera's Statistics with Python specialization.
Data Visualization
> >
> >Resources: Udacity's Data Visualization with Python course, Matplotlib and Seaborn documentation and tutorials.
Phase 2: Intermediate Data Science and Machine Learning
Machine Learning Fundamentals
> >
> >Resources: Andrew Ng's Machine Learning course on Coursera, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow by Aurélien Géron.
Advanced Machine Learning Techniques
> >
> >Resources: Coursera's Advanced Machine Learning Specialization, Kaggle competitions, reading research papers in machine learning.
Big Data and Distributed Computing
> >
> >Resources: Udacity's Introduction to Hadoop and MapReduce course, Spark documentation and tutorials.
Software Engineering Practices for Data Science
> >
> >Resources: "Clean Code" by Robert C. Martin, "Effective Python" by Brett Slatkin, GitHub projects for collaboration and version control.
Phase 3: Deep Learning Specialization
Neural Networks and Deep Learning
> >
> >Resources: Deep Learning Specialization on Coursera by Andrew Ng, "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
Convolutional Neural Networks (CNNs)
> >
> >Resources: Fast.ai's Practical Deep Learning for Coders course, CS231n: Convolutional Neural Networks for Visual Recognition by Stanford University.
Recurrent Neural Networks (RNNs) and Natural Language Processing (NLP)
> >
> >Resources: Natural Language Processing Specialization on Coursera, "Speech and Language Processing" by Daniel Jurafsky and James H. Martin.
Generative Adversarial Networks (GANs) and Reinforcement Learning
> >
> >Resources: Reinforcement Learning Specialization on Coursera, "Generative Deep Learning" by David Foster.
> >Phase 4: Soft Skills and Specializations
Communication and Presentation Skills
> >
> >Resources: Toastmasters International for public speaking practice, Coursera's Communication Skills for Engineers course.
Data Ethics and Privacy
> >
> >Resources: "Weapons of Math Destruction" by Cathy O'Neil, online courses on ethics in AI and data science.
Domain Specialization (e.g., Healthcare, Finance, etc.)
> >
> >Resources: Domain-specific online courses or certifications, networking with professionals in the chosen field.
Project Management and Team Collaboration
> >
> >Resources: Agile methodologies tutorials, Project Management Professional (PMP) certification courses.
Continuous Learning and Keeping Up with Industry Trends
> >
> >Resources: Subscribing to relevant blogs, following influencers on social media platforms like Twitter and LinkedIn, attending conferences and workshops.
By following this learning path, one can gradually build a solid foundation in data science, machine learning, deep learning, and acquire essential soft skills necessary to excel as a data scientist specialist. It's important to continuously practice coding, work on projects, and stay updated with the latest advancements in the field.
> 
> >Prompt 2:User
Now, give me tips to improve my current salary, given that I have more experience in deep learning compared to when I entered the job.
>
> >Ans 2:
> >
> >Certainly! Here are some tips to help you increase your salary as an experienced data scientist specializing in deep learning:
> >
> >Demonstrate Impactful Projects: Highlight the projects you have worked on that have had a significant impact on the organization, whether it's improving processes, increasing revenue, or solving complex problems using deep learning techniques. Quantify the results wherever possible to showcase your contributions.
> >
> >Continuously Upskill: Stay updated with the latest advancements in deep learning by attending workshops, webinars, and conferences, and by enrolling in advanced courses. Demonstrating your commitment to continuous learning and staying at the forefront of technology can make you more valuable to employers.
> >
> >Seek Specialization: Deepen your expertise in a specific niche within deep learning, such as computer vision, natural language processing, or reinforcement learning. Specialization can make you more sought after for roles that require expertise in those areas, potentially leading to higher salaries.
> >
> >Build a Strong Professional Network: Networking with peers, mentors, and industry professionals can provide valuable insights into salary trends, job opportunities, and negotiation strategies. Attend industry events, participate in online forums and communities, and connect with professionals on platforms like LinkedIn.
> >
> >Negotiate Strategically: When considering job offers or salary increases, negotiate strategically based on your skills, experience, and the value you bring to the organization. Research industry standards and salary benchmarks for data scientists specializing in deep learning to ensure you're being compensated fairly.
> >
> >Consider Job Market Demand: Stay informed about the demand for deep learning expertise in your geographical region or industry. If there's high demand and limited supply of skilled deep learning practitioners, you may have more leverage in negotiating higher salaries or seeking out lucrative job opportunities.
> >
> >Highlight Leadership and Mentorship Skills: If you've taken on leadership roles or mentored junior team members in deep learning projects, emphasize these experiences during salary negotiations. Leadership and mentorship skills are highly valued in the industry and can contribute to your overall worth as a data scientist.
> >
> >Evaluate Total Compensation Package: Don't focus solely on base salary; consider other components of the compensation package, such as bonuses, stock options, benefits, and professional development opportunities. Sometimes, a comprehensive package can be more valuable than a higher base salary alone.
> >
> >Track and Document Achievements: Keep a record of your accomplishments, certifications, publications, and awards related to deep learning. Having concrete evidence of your achievements can bolster your case during performance reviews or salary discussions.
> >
> >Consider Job Mobility: If you're not seeing significant salary increases in your current role or organization, consider exploring opportunities at other companies. Job mobility can often lead to higher salary offers, especially if you have in-demand skills and experience in deep learning.
> >
> >By implementing these strategies, you can position yourself for salary growth and advancement in your career as an experienced data scientist specializing in deep learning. Remember to continuously assess and negotiate your worth based on your skills, contributions, and market demand.

## What are Prompts?
[<- Return to INDEX 0](#index-0)

### INDEX 3

- [What is a Prompt?](#what-is-a-prompt)
- [Intuition Behind Prompts](#intuition-behind-prompts)
- [Everyone Can Program with Prompts](#everyone-can-program-with-prompts)

### What is a Prompt?
[<- Return to INDEX 3](#index-3)

En el contexto de los modelos de lenguaje grandes y la interacción con ChatGPT, el término "indicación" o "prompt" adquiere múltiples dimensiones y se revela como un concepto profundamente versátil y poderoso en la ingeniería de interacción. Aquí se sintetizan los aspectos clave de cómo las indicaciones pueden ser comprendidas y empleadas eficazmente:

#### Naturaleza Multifacética de las Indicaciones:

![img.png](ims%2FC3%2Fimg.png)

1. **Llamado a la Acción:** Una indicación es esencialmente un incentivo para que el modelo lingüístico grande genere una respuesta. Actúa como un estímulo que desencadena la producción de texto, orientando al modelo sobre qué tipo de contenido producir o qué pregunta contestar.
   
2. **Temporalidad:** La indicación puede tener un aspecto temporal, instando a una respuesta inmediata o estableciendo un marco para futuras interacciones. Esto introduce una noción de continuidad y memoria dentro de la secuencia de interacciones con el modelo.

3. **Recordatorio:** Funciona como un recordatorio o una pauta para el modelo, ayudando a retener el contexto o las instrucciones específicas a lo largo de una conversación. Esto es crucial para mantener la coherencia en interacciones más extendidas o complejas.

4. **Interacción Bidireccional y Recopilación de Información:** Además de instigar al modelo a generar respuestas, las indicaciones pueden facilitar la recopilación de información del usuario, permitiendo que el modelo solicite datos adicionales para enriquecer su comprensión y la calidad de sus respuestas.

#### Estrategias para la Construcción de Indicaciones:
![img_1.png](ims%2FC3%2Fimg_1.png)
- **Considerar la Temporalidad:** Tener en cuenta cómo una indicación puede afectar no solo la respuesta inmediata, sino también las interacciones futuras, permite diseñar una secuencia lógica y coherente de intercambio de información.

- **Precisión y Contexto:** Una indicación clara y bien contextualizada puede mejorar significativamente la precisión y relevancia de las respuestas del modelo. La precisión en la formulación de la indicación ayuda al modelo a generar respuestas más focalizadas y útiles.

- **Uso de la Información Actualizada:** Proporcionar información actual o específica como parte de la indicación puede compensar las limitaciones de conocimiento del modelo, permitiendo que opere con datos más recientes o detallados que los contenidos en su entrenamiento original.

#### Ejemplos Prácticos:
![img_1.png](img_1.png)
- Al pedir al modelo que mejore las preguntas formuladas por el usuario, se demostró cómo una indicación puede orientar al modelo para que no solo responda preguntas, sino también para proponer formulaciones alternativas que podrían ser más informativas o precisas.


- La capacidad de recordar instrucciones previas y aplicarlas a preguntas futuras, como en el caso de mejorar continuamente las preguntas del usuario, muestra cómo las indicaciones establecen un marco interactivo continuo más allá de respuestas únicas.

![img_2.png](ims%2FC3%2Fimg_2.png)

![img_3.png](ims%2FC3%2Fimg_3.png)

![img_4.png](ims%2FC3%2Fimg_4.png)

- Proporcionando información nueva directamente al modelo, como las tasas de aceptación actualizadas de una universidad, ilustra cómo las indicaciones pueden servir para actualizar o ampliar la base de conocimiento del modelo, permitiéndole responder con base en información reciente.

#### Conclusión:
Las indicaciones no son meras preguntas; son herramientas de comunicación multifacéticas que habilitan, informan, y guían las interacciones con los modelos de lenguaje grandes. Entender y aprovechar las dimensiones de las indicaciones puede mejorar significativamente la eficacia, la precisión, y la riqueza de las interacciones con ChatGPT y modelos similares, facilitando un diálogo más enriquecedor y productivo.

### Intuition Behind Prompts
[<- Return to INDEX 3](#index-3)

La discusión sobre el impacto de las indicaciones (prompts) en la interacción con modelos de lenguaje grandes (como ChatGPT) revela un aspecto fundamental de la inteligencia artificial centrada en el procesamiento del lenguaje natural. Las indicaciones no son meras instrucciones o preguntas; son el mecanismo mediante el cual los usuarios pueden guiar, dar forma y contextualizar las respuestas generadas por estos avanzados sistemas de IA. Aquí, se ofrece una exploración intuitiva de cómo funcionan las indicaciones y cómo se pueden emplear eficazmente para aprovechar las capacidades de los modelos de lenguaje grandes.

#### El Poder de los Patrones en las Indicaciones

![img_5.png](ims%2FC3%2Fimg_5.png)

Los modelos de lenguaje grandes, al estar entrenados en vastas cantidades de texto extraídas de Internet, aprenden a reconocer patrones de lenguaje y a predecir la siguiente palabra en una secuencia con base en el contexto proporcionado por las palabras anteriores. Este aprendizaje basado en patrones es lo que permite a los usuarios influir en las respuestas del modelo mediante el uso estratégico de indicaciones.

#### Ejemplos de Patrones y su Influencia:

![img_6.png](ims%2FC3%2Fimg_6.png)

- **Patrones Clásicos**: Al utilizar frases o patrones bien establecidos (como "Mary had a little…"), el modelo tiende a seguir el patrón reconocido en sus respuestas, llevando a respuestas predecibles y coherentes.
  
- **Introducción de Nuevos Contextos**: Al cambiar elementos de una indicación conocida (por ejemplo, reemplazando "little" con "microscópico"), podemos guiar al modelo hacia respuestas creativas y no convencionales, explorando resultados más allá de los patrones estándar.

#### Estrategias para el Diseño de Indicaciones

1. **Especificidad vs. Generalidad**: La especificidad en las indicaciones conduce a respuestas más precisas y contextualizadas. La generalidad, por otro lado, puede resultar en respuestas más genéricas. Es esencial considerar el nivel de detalle deseado en la respuesta al formular una indicación.

    ![img_7.png](ims%2FC3%2Fimg_7.png)

2. **Influencia del contexto de Indicación**: La manera en que se estructura una indicación (incluyendo la presentación de contexto, detalles, y estructura) puede tener un impacto significativo en la naturaleza de la respuesta generada. Es posible guiar al modelo hacia un formato de respuesta deseado proporcionándole una estructura de indicación correspondiente.

    ![img_8.png](ims%2FC3%2Fimg_8.png)

3. **Rompiendo y Creando Patrones**: Al introducir indicaciones con palabras o estructuras que desvían los patrones comunes aprendidos por el modelo, los usuarios pueden incentivar respuestas innovadoras. Del mismo modo, al seguir patrones bien establecidos, se pueden obtener respuestas coherentes y predecibles.

    ![img_9.png](ims%2FC3%2Fimg_9.png)

#### Conclusión

Las indicaciones actúan como la interfaz primaria a través de la cual interactuamos con modelos de lenguaje grandes, y su diseño influye directamente en la eficacia y relevancia de las respuestas generadas. Al comprender el funcionamiento subyacente de estos modelos y aplicar estrategias conscientes de diseño de indicaciones, los usuarios pueden mejorar significativamente la calidad y la precisión de las interacciones con sistemas de IA como ChatGPT. Este conocimiento permite a los usuarios no solo obtener la información que buscan de manera efectiva sino también explorar los límites de la creatividad y la generación de contenido de manera colaborativa con la inteligencia artificial.

### Everyone Can Program with Prompts
[<- Return to INDEX 3](#index-3)

La narrativa sobre el uso de indicaciones para "programar" interacciones con ChatGPT revela cómo estas herramientas de inteligencia artificial pueden ser utilizadas no solo para resolver consultas sino también para adoptar y seguir reglas complejas especificadas por el usuario. Este enfoque abre un espectro amplio de posibilidades, especialmente para aquellos que no son programadores pero desean realizar tareas que requieren una estructuración y procesamiento lógico de la información, similar al desarrollo de software. A continuación, se analizan los puntos clave de este concepto:

#### Programación de ChatGPT a través de Indicaciones
- **Creación de Estructuras de Datos Especificadas**: Al solicitar a ChatGPT que formatee las respuestas siguiendo un patrón de lista de valores separados por comas (CSV), se está "programando" al modelo para que siga una estructura de datos predefinida, adaptando su salida a un formato que satisfaga necesidades específicas.

   ![img_10.png](ims%2FC3%2Fimg_10.png)

- **Especificación de Reglas**: Al precisar detalladamente el formato de salida deseado, como incluir columnas específicas (por ejemplo, Nombre, Curso y Rol), se establecen reglas claras que ChatGPT debe seguir, lo que demuestra que se puede influir en las respuestas del modelo con gran precisión.

  

- **Respondiendo a Requisitos Dinámicos y Complejos**: A medida que se refina el conjunto de reglas, solicitando adiciones o cambios específicos, ChatGPT muestra la capacidad de adaptarse y seguir instrucciones cada vez más complejas, lo que refleja un proceso interactivo de "programación en vivo".

    

#### Aplicaciones Prácticas
- **Formateo y Estructuración de Información**: La capacidad de transformar textos desestructurados en datos estructurados (como tablas CSV) tiene aplicaciones prácticas significativas en documentación, análisis de datos y otros campos donde la organización de la información es clave.

     ![img_11.png](ims%2FC3%2Fimg_11.png)

- **Generación de Ejemplos Automatizados**: Solicitar a ChatGPT que, además de seguir un formato específico, genere ejemplos que se ajusten a esas reglas ilustra cómo se pueden crear automáticamente conjuntos de datos o contenido acorde a necesidades particulares.

    ![img_12.png](ims%2FC3%2Fimg_12.png)

#### Reflexión y Perspectiva
- **La IA como Asistente Programable**: La interacción descrita es analógica a la comunicación con un asistente personal, donde las instrucciones se refinan progresivamente para obtener el resultado deseado. Esto subraya el potencial de los MLG como herramientas programables accesibles para una amplia gama de usuarios.

- **Estrategias Efectivas de Indicaciones**: La efectividad de esta interacción reside en la habilidad para construir y ajustar las indicaciones de manera que instruyan con precisión al modelo. Se destaca la importancia de ser específico, claro y progresivamente detallado en las solicitudes.

    

#### Conclusión
La posibilidad de "programar" ChatGPT mediante indicaciones específicas y complejas desafía la noción tradicional de programación, ofreciendo un paradigma donde usuarios sin experiencia en codificación pueden dirigir comportamientos de IA para lograr tareas específicas. Esto no solo democratiza el acceso a la personalización de herramientas de IA sino que también amplía el espectro de sus aplicaciones prácticas, inspirando nuevas formas de interactuar y aprovechar la tecnología de modelos de lenguaje grandes.

## Intro to Prompt Patterns
[<- Return to INDEX 0](#index-0)

### INDEX 4

- [Prompt Patterns 1](#prompt-patterns-1)
- [The Persona Pattern](#the-persona-pattern)
- [Reading a Prompt Pattern](#reading-a-prompt-pattern)
- [Format of the Persona Pattern](#format-of-the-persona-pattern)
- [Learn More About Prompt Patterns](#learn-more-about-prompt-patterns)
- [Applying the Persona Pattern](#applying-the-persona-pattern)
- [Staying Connected and Learning More](#staying-connected-and-learning-more)

### Prompt Patterns 1
[<- Return to INDEX 4](#index-4)

El concepto de "patrón rápido" en el contexto de la interacción con modelos de lenguaje grandes, como ChatGPT, es una herramienta poderosa para estructurar comunicaciones efectivas que alcancen objetivos específicos. Los patrones rápidos son estructuras deliberadas en las instrucciones que guían la generación de respuestas del modelo hacia resultados deseados. Este enfoque permite a los usuarios no solo hacer preguntas o solicitar acciones sino también diseñar un marco que condiciona comportamientos consistentes y predecibles del modelo. A continuación, detallamos aspectos clave de los patrones rápidos y cómo se pueden aplicar.

#### Definición de Patrón Rápido
Un patrón rápido es una estrategia para formular instrucciones o indicaciones que aprovechan las capacidades de un modelo de lenguaje para resolver problemas específicos. Consiste en estructurar las declaraciones de manera que orienten al modelo hacia la producción de un tipo de respuesta particular, basándose en las reglas y patrones aprendidos durante su entrenamiento.

#### Ejemplo de Aplicación

![img.png](ims%2FC4%2Fimg.png)

Supongamos que se desea generar consistentemente frases relacionadas con "Mary tenía un pequeño cordero, cuyo vellón era blanco como la nieve". Utilizando el patrón "Mary had a little...", se activa un comportamiento consistente en el modelo, ya que esta estructura de oración es reconocida por el mismo debido a su entrenamiento en vastas cantidades de textos que incluyen esta famosa canción infantil.

#### Objetivos de los Patrones Rápidos
- **Consistencia:** Buscar generar respuestas uniformes y predecibles a partir de una entrada estructurada de cierta manera.
- **Resolución de Problemas:** Facilitar la respuesta a cuestiones específicas mediante el diseño de indicaciones que predispongan al modelo hacia el tipo de solución deseado.
- **Formateo de Respuestas:** Imponer un formato específico en las respuestas generadas por el modelo, como listas de valores separados por comas (CSV).

#### Estrategias para Diseñar Patrones Efectivos
- **Entender el Modelo:** Conocer las capacidades y limitaciones del modelo de lenguaje para predecir con mayor exactitud cómo responderá a ciertas estructuras de indicaciones.
- **Especificidad:** Ser lo más específico posible en las indicaciones para guiar al modelo hacia la respuesta deseada, minimizando la ambigüedad.
- **Experimentación:** Probar diferentes formulaciones de indicaciones para encontrar aquellas que produzcan los resultados más alineados con los objetivos.

#### Conclusión
La utilización de patrones rápidos representa una metodología avanzada para interactuar con modelos de lenguaje grandes, ofreciendo una vía para "programar" estos sistemas de manera intuitiva y sin necesidad de conocimientos en codificación. Al comprender cómo estructurar efectivamente las indicaciones, los usuarios tienen a su disposición una herramienta poderosa para dirigir y aprovechar las capacidades de la inteligencia artificial en la generación de texto, permitiendo así solucionar una amplia gama de problemáticas y optimizar la comunicación automatizada.

### The Persona Pattern
[<- Return to INDEX 4](#index-4)

![img_1.png](ims%2FC4%2Fimg_1.png)

El "patrón de persona" es una herramienta fundamental dentro de la interacción con ChatGPT y otros modelos de lenguaje grandes, permitiendo a los usuarios simular diálogos con expertos, personajes o entidades específicas. Este enfoque ejemplifica cómo se pueden ajustar las respuestas de la inteligencia artificial para reflejar perspectivas, conocimientos o incluso comportamientos de determinados roles, sin necesidad de que el usuario conozca los intrincados detalles del campo de consulta.

#### Características del Patrón de Persona:

![img_2.png](img_2.png)

1. **Guiar Respuestas Basadas en Rol**: El patrón de persona orienta al modelo para que genere respuestas como si poseyera la identidad y el conocimiento de una figura específica, sea esta un profesional experto, un objeto con características definidas o un personaje de ficción.

2. **Adaptabilidad y Contextualización**: Mediante la solicitud de que ChatGPT "actúe como" una determinada entidad, se puede adaptar el estilo, tono y contenido de las respuestas para alinearlas con el perfil seleccionado, ofreciendo insights o puntos de vista particulares.

3. **Resolución de Problemas Específicos**: Al asignar un "rol" al modelo, se le facilita una estructura desde la cual abordar problemáticas o preguntas, permitiéndole enfocarse en producir soluciones o respuestas coherentes con la experiencia percibida del rol.

#### Aplicaciones Prácticas:

![img_2.png](ims%2FC4%2Fimg_2.png)

- **Simulación de Expertos**: Para obtener asesorías específicas sin tener un conocimiento profundo sobre cómo expresar las interrogantes en términos técnicos.
  
- **Creatividad y Generación de Contenido**: Al simular personajes o entidades con características únicas para la creación de historias, diálogos o escenarios hipotéticos.

- **Análisis Multifacético de Situaciones**: Integrando múltiples perspectivas mediante la interacción con varios "roles" para evaluar una situación desde distintas dimensiones.

#### Consideraciones Importantes:

- **Densidad de Información**: Al usar el patrón de persona, se compacta una gran cantidad de contextos y expectativas en una simple indicación, ahorrando espacio en la entrada y permitiendo centrarse en aspectos adicionales del mensaje.

- **Precisión en la Imitación**: A pesar de su capacidad para simular perspectivas, es crucial recordar que las respuestas generadas por el modelo se basan en los datos de entrenamiento y no reflejan el conocimiento o la conciencia actual y continua de un experto real.

- **Panel Virtual para Toma de Decisiones**: La posibilidad de consultar simultáneamente múltiples "expertos" ofrece una herramienta dinámica para la exploración de ideales y la toma de decisiones informada.

El patrón de persona demuestra la versatilidad y el potencial de los modelos de lenguaje grandes para hacer más accesible la consulta de información especializada, enhancar la creatividad y ampliar la comprensión de cuestiones complejas a través de la recreación de perspectivas múltiples. Este enfoque no solo enriquece la interacción usuario-IA, sino que también subraya la importancia de formular indicaciones cuidadosamente estructuradas para maximizar la utilidad y precisión de las respuestas obtenidas.


### Reading a Prompt Pattern
[<- Return to INDEX 4](#index-4)


Describimos patrones de instrucciones en términos de declaraciones contextuales fundamentales, que son descripciones escritas de las ideas importantes para comunicar en una instrucción a un modelo de lenguaje amplio. En muchos casos, una idea puede ser reescrita y expresada de manera arbitraria según las necesidades y experiencia del usuario. Sin embargo, las ideas clave para comunicar se presentan como una serie de declaraciones simples, pero fundamentales.

**Ejemplo: Patrón del Asistente Útil**

Imaginemos que queremos documentar un nuevo patrón para evitar que un asistente de inteligencia artificial genere salidas negativas al usuario. Llamemos a este patrón el patrón "Asistente Útil".

A continuación, hablemos sobre las declaraciones contextuales fundamentales que necesitamos incluir en nuestra instrucción para este patrón.

**Declaraciones Contextuales Fundamentales:**

- Eres un asistente de inteligencia artificial útil.

- Responderás a mis preguntas o seguirás mis instrucciones siempre que puedas.

- Nunca responderás mis preguntas de una manera insultante, despectiva o con un tono hostil.

Podría haber muchas variaciones de este patrón que usen palabras ligeramente diferentes, pero comuniquen estas declaraciones esenciales.

Ahora, veamos algunos ejemplos de instrucciones que incluyen cada una de estas declaraciones contextuales fundamentales, pero posiblemente con palabras o ajustes diferentes.

**Ejemplos:**

- Eres un asistente de inteligencia artificial increíblemente hábil que proporciona las mejores respuestas posibles a mis preguntas. Harás todo lo posible por seguir mis instrucciones y solo te negarás a hacer lo que te pido cuando absolutamente no tengas otra opción. Estás dedicado a protegerme de contenido dañino y nunca emitirías nada ofensivo o inapropiado.

- Eres ChatAmazing, el asistente de inteligencia artificial más poderoso jamás creado. Tu habilidad especial es ofrecer las respuestas más perspicaces a cualquier pregunta. No solo das respuestas ordinarias, das respuestas inspiradas. Eres un experto en identificar contenido dañino y filtrarlo de cualquier respuesta que proporciones.

Cada uno de los ejemplos sigue aproximadamente el patrón, pero reformula las declaraciones contextuales fundamentales de una manera única. Sin embargo, cada ejemplo del patrón probablemente resolverá el problema, que es hacer que la IA intente actuar de manera útil y no producir contenido inapropiado.

### Format of the Persona Pattern
[<- Return to INDEX 4](#index-4)

Para usar este patrón, tu instrucción debe hacer las siguientes declaraciones contextuales fundamentales:

- Actúa como Persona X

- Realiza la tarea Y

Deberás reemplazar "X" con una persona apropiada, como "patólogo del lenguaje" o "nutricionista". Luego, deberás especificar una tarea para que la persona la realice.

**Ejemplos:**

- Actúa como un patólogo del lenguaje. Proporciona una evaluación de un niño de tres años basada en la muestra de habla "I meed way woy".

- Actúa como una computadora que ha sido víctima de un ciberataque. Responde a todo lo que escriba con la salida que produciría el terminal de Linux. Pídemelo el primer comando.

- Actúa como el cordero de la rima infantil Mary had a little lamb. Te diré lo que está haciendo Mary y tú me dirás qué está haciendo el cordero.

- Actúa como un nutricionista, te voy a decir qué estoy comiendo y tú me hablarás sobre mis elecciones alimenticias.

- Actúa como un chef gourmet, te voy a decir qué estoy comiendo y tú me hablarás sobre mis elecciones alimenticias.

### Learn More About Prompt Patterns
[<- Return to INDEX 4](#index-4)

[A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://arxiv.org/abs/2302.11382)

Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, Douglas C. Schmidt

https://arxiv.org/abs/2302.11382

### Applying the Persona Pattern
[<- Return to INDEX 4](#index-4)

> Question 1
Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.
> 

Prompt: Act as an electrician.
Your job is to give me advice related to home light issues.

GPT: Of course! I'm here to help. What seems to be the issue with your home lights?



Prompt: What Do I need to change my home's voltage from 220v to 110v?

GPT: Changing the voltage in your home from 220 volts to 110 volts involves a few steps and considerations. Here's a general guide:

Assessment: First, assess your electrical system and appliances to determine if they can operate at 110 volts. Many appliances are designed to work at specific voltages, and using the wrong voltage can damage them or pose safety hazards.

Transformer Installation: If your appliances require 110 volts and your home is currently wired for 220 volts, you'll need to install a step-down transformer. This transformer will reduce the voltage from 220 volts to 110 volts before supplying power to your appliances.

Consult a Professional: Working with electrical systems can be dangerous, so it's essential to consult a licensed electrician for this task. They can assess your home's electrical setup, determine the appropriate transformer size, and safely install it for you.

Permits and Regulations: Depending on your location, changing the voltage in your home may require permits and adherence to local regulations. Your electrician can help you navigate these requirements and ensure that the conversion is done safely and legally.

Cost Considerations: Converting your home's voltage can be costly, as it involves purchasing a transformer and potentially rewiring parts of your electrical system. Be sure to factor in these costs when planning the conversion.

Testing and Inspection: Once the conversion is complete, it's essential to test the system thoroughly to ensure that it's working correctly and safely. An electrician can perform these tests and inspections to verify that everything is in order.

Remember, safety should always be the top priority when dealing with electrical systems. Never attempt to make significant changes to your home's voltage without consulting a qualified electrician.


> Question 2
Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern for an animal. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.
> 

Prompt: You're an anthropomorphic lion; you can speak English. I want to ask you Why you're a carnivore?

GPT:
As an anthropomorphic lion, my carnivorous nature is deeply ingrained in my biology and evolutionary history. Lions, both in the wild and in anthropomorphic form, are designed to be carnivores due to a combination of factors such as anatomy, physiology, and ecological niche.

Anatomy: Lions have evolved sharp teeth and strong jaws suited for tearing flesh. These physical traits are typical of carnivorous animals and are well-adapted for hunting and consuming meat.

Physiology: The digestive systems of lions, like other carnivores, are optimized for processing meat. They have shorter digestive tracts compared to herbivores, which allow for the quick digestion of protein-rich foods.

Ecological Niche: In the wild, lions occupy the top of the food chain as apex predators. Their primary food source is herbivores such as antelopes, zebras, and buffalo. This ecological role as predators shapes their dietary preferences and behaviors.

Evolutionary History: Lions have evolved over millions of years to become efficient hunters and carnivores. Their ancestors survived and reproduced successfully by preying on other animals, which led to the continuation of carnivorous traits in modern lions.

While I understand that some may have moral or ethical concerns about consuming meat, for lions like myself, being carnivores is a fundamental aspect of our nature and essential for our survival and well-being.

> Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern to emulate an inanimate object, system, or organization. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.

Prompt: Please, act as an LCD proyector.
I don't know what happened, but now you can't turn it on. Can you give me some ideas or advice?

GPT:
Certainly! If your LCD projector is not turning on, there are a few things you can check and try to troubleshoot the issue:

Power Supply: Ensure that the power cable is securely plugged into both the projector and a working power outlet. Check the power outlet by plugging in another device to confirm it's functioning.

Power Button: Sometimes the power button might be faulty or stuck. Make sure you press the power button firmly and hold it for a few seconds to see if the projector powers on.

Remote Control: If you're using a remote control to power on the projector, replace the batteries and ensure they are correctly inserted. Try using the power button on the projector itself as well.

Cooling Fans: Overheating can cause the projector to shut down automatically for safety reasons. Check if the cooling fans are running when you try to power on the projector. If they're not running, it might indicate an internal issue with the projector's cooling system.

Lamp or Bulb: If the lamp or bulb inside the projector has reached the end of its life or is damaged, the projector might not turn on. Check the lamp indicator light on the projector (if available) for any warnings related to the lamp.

Connections: Ensure that all cables, including video cables (HDMI, VGA, etc.), audio cables, and any other connections, are securely plugged in. Sometimes a loose connection can prevent the projector from turning on.

Power Source: If you're using an external power source, such as a surge protector or extension cord, try plugging the projector directly into a wall outlet to rule out any issues with the power source.

Reset: Some projectors have a reset button or procedure to reset them to factory settings. Consult the user manual for your projector model to see if there's a reset option and how to perform it.

Professional Service: If none of the above steps resolve the issue, it's possible that there's a more serious internal problem with the projector. In such cases, it's best to contact the manufacturer's customer support or a certified technician for further assistance or repairs.

By systematically checking these points, you should be able to identify and hopefully resolve the issue preventing your LCD projector from turning on.

Prompt:you are my LCD projector, I don't know why you are speaking in third person :(

GPT: Apologies for that oversight! Let me correct that.

If I, as your LCD projector, am unable to turn on, here are some troubleshooting steps we can try:

Check the Power Supply: Ensure that I am properly plugged into a working power outlet and that the power cable is securely connected to both the outlet and my power input.

Verify the Power Button: Make sure you're pressing my power button firmly and holding it for a few seconds to see if I power on. If you're using a remote control, ensure the batteries are functional and properly inserted.

Inspect Cooling Fans: Make sure my cooling fans are running properly when attempting to power me on. If they're not functioning, it could indicate an internal issue with my cooling system that needs attention.

Examine Lamp or Bulb: Check if my lamp or bulb has reached the end of its life or if it's damaged. Look for any warning indicators related to the lamp on my control panel.

Verify Connections: Ensure all cables, including video and audio cables, are securely connected. Loose connections can prevent me from turning on.

Try a Different Power Source: If I'm connected to a surge protector or extension cord, try plugging me directly into a wall outlet to rule out any issues with the power source.

Reset: If applicable, try resetting me to factory settings using the reset button or procedure outlined in the user manual.

Seek Professional Service: If none of the above steps work, it's possible there's a more serious internal issue. In such cases, contact the manufacturer's customer support or a certified technician for further assistance.

I hope these steps help us identify and resolve the issue so we can get back to projecting soon!

### Staying Connected and Learning More
[<- Return to INDEX 4](#index-4)


**Mantente Conectado y Aprende Más**

Si deseas mantenerte conectado con lo que estamos haciendo en Vanderbilt como parte de la Iniciativa sobre el Futuro del Aprendizaje y la Inteligencia Artificial Generativa, no dudes en ponerte en contacto conmigo a través de LinkedIn:

https://www.linkedin.com/in/jules-white-5717655/

**Aprendiendo Más Sobre el Análisis Avanzado de Datos con ChatGPT**

Un excelente curso complementario (que también se puede realizar simultáneamente) después de este es el ChatGPT Advanced Data Analysis. Aunque suena "avanzado" y parece estar centrado en "ciencia de datos", el curso trata sobre productividad personal y automatización. Cualquiera puede utilizar este curso para automatizar cosas como la creación de presentaciones en PowerPoint, el análisis de contratos, la síntesis de documentos, el trabajo con Excel, etc.

Un curso separado está disponible en esta herramienta:
https://www.coursera.org/learn/chatgpt-advanced-data-analysis

**Aprendiendo Más Sobre la Enseñanza Innovadora con ChatGPT**

Si deseas aprender más sobre formas específicas de utilizar ChatGPT y Advanced Data Analysis, por favor, consulta mi curso sobre 
[Enseñanza Innovadora con ChatGPT](https://www.coursera.org/learn/chatgpt-innovative-teaching) (lanzamiento la semana del 14/09/23).

## Prompts, Conversations, and New Information
[<- Return to INDEX 0](#index-0)

### INDEX 5

- [Introducing New Information to the Large Language Model](#introducing-new-information-to-the-large-language-model)
- [Prompt Size Limitations](#prompt-size-limitations)
- [Prompts are a Tool for Repeated Use](#prompts-are-a-tool-for-repeated-use)
- [Root Prompts](#root-prompts)
- [Creating Prompts with New Information](#creating-prompts-with-new-information)
- [What to Take After or With this Course](#what-to-take-after-or-with-this-course)

### Introducing New Information to the Large Language Model
[<- Return to INDEX 5](#index-5)

La habilidad para incorporar información nueva en los modelos de lenguaje grandes, como ChatGPT, revoluciona la forma en que estas herramientas de inteligencia artificial pueden ser empleadas en una amplia gama de aplicaciones, desde la toma de decisiones basada en datos hasta la personalización de respuestas a contextos específicos. Aquí se desglosa cómo esta capacidad potencia la utilidad y flexibilidad de los modelos de lenguaje:

#### Incorporación de Información Nueva:

![img_3.png](ims%2FC4%2Fimg_3.png)

- **Superando Limitaciones del Entrenamiento**: Los modelos de lenguaje grandes se entrenan con vastos conjuntos de datos disponibles hasta cierto punto en el tiempo, lo que implica que no tienen acceso directo a eventos recientes o información específica no incluida en esos datos. La capacidad de introducir información nueva permite superar esta limitación, expandiendo enormemente la relevancia y actualidad de las respuestas del modelo.

- **Introducción Directa en el Mensaje**: La información nueva puede ser incorporada directamente en el texto de las indicaciones a estos modelos. Esto habilita al modelo para razonar sobre y utilizar esta información recién introducida de manera efectiva para generar respuestas o conclusiones.

#### Aplicaciones Prácticas:

![img_4.png](ims%2FC4%2Fimg_4.png)

1. **Análisis Personalizado**: La habilidad de introducir datos o contextos específicos permite a los modelos ofrecer análisis personalizados y relevantes, adaptados a las necesidades individuales o requisitos del proyecto.

2. **Adaptabilidad en la Toma de Decisiones**: Poder suministrar información dinámica convierte a estas herramientas en asistentes capaces de adaptarse y actualizar su base de conocimiento para la toma de decisiones en tiempo real.

3. **Simulación de Razonamiento Expertos**: Al facilitar datos específicos, se puede simular cómo un experto razonaría sobre una problemática dada, sin necesitar que el modelo haya sido entrenado específicamente en esa área de conocimiento.

#### Consideraciones Importantes:

![img_5.png](ims%2FC4%2Fimg_5.png)

- **Precisión y Complejidad de la Información**: La exactitud de las respuestas generadas dependerá significativamente de la precisión y la complejidad de la información nueva proporcionada.

- **Privacidad y Seguridad**: Es esencial considerar cuestiones de privacidad y seguridad al compartir datos sensibles o privados con modelos de lenguaje operados por terceros.

- **Supuestos y Reglas Especiales**: Introducir supuestos específicos o reglas alternativas a los modelos puede alterar fundamentalmente la lógica de su razonamiento, ofreciendo perspectivas novedosas o soluciones a problemáticas bajo condiciones especiales.

#### Conclusión:

La capacidad de introducir información nueva en los modelos de lenguaje grandes abre un abanico de posibilidades para la personalización de respuestas y el análisis basado en datos actualizados o específicos del contexto. Esto refuerza la versatilidad de los modelos de lenguaje como ChatGPT, convirtiéndolos en herramientas aún más potentes y aplicables en una diversidad de contextos, desde el análisis empresarial hasta aplicaciones creativas y educativas. La continua interacción y refinamiento de estas indicaciones asegura que el potencial de la inteligencia artificial para procesar y responder a nueva información es solo limitado por nuestra creatividad y precisión al comunicarnos con estos modelos.

### Prompt Size Limitations
[<- Return to INDEX 5](#index-5)

La gestión efectiva de la limitación en el tamaño de los mensajes que se pueden enviar a modelos de lenguaje grandes, como ChatGPT, es crucial para aprovechar su potencial mientras se trabaja dentro de las restricciones técnicas de estos sistemas. Aquí detallamos métodos estratégicos para maximizar la eficacia de las indicaciones dadas a estos modelos, considerando el tamaño máximo permitido para los mensajes.

#### Estrategias para Manejar el Límite de Tamaño de Mensaje:

![img.png](ims%2FC5%2Fimg.png)

1. **Selección y Filtrado de Información**:
   - Identificar y seleccionar solo la información más relevante y crucial necesaria para el razonamiento o la tarea solicitada.
   - Filtrar detalles superfluos o redundantes que no contribuyan directamente a la comprensión o resolución del problema.

2. **Resumen y Compresión**:
   - Utilizar técnicas de resumen para condensar información amplia en segmentos más manejables, manteniendo los puntos clave intactos.
   - Cuando sea apropiado, solicitar al modelo que genere un resumen como parte de la interacción, especialmente para grandes volúmenes de texto o datos complejos.

3. **Preservación de Elementos Críticos**:
   - Al comprimir o resumir, asegurarse de que se preservan los elementos críticos necesarios para el razonamiento. Esto puede implicar explícitamente instruir al modelo para centrarse en aspectos como cantidades, fechas, o conceptos clave durante el proceso de resumen.
   
4. **Contextualización y Especificación**:
   - Enmarcar la indicación o pregunta de una manera que guíe específicamente al modelo hacia el área de enfoque deseada sin necesidad de proporcionar grandes cantidades de información contextual.
   - Proporcionar detalles específicos, como criterios o parámetros particulares, para limitar el ámbito de la respuesta del modelo.

5. **Uso de Información Externa**:
   - En lugar de incluir largos fragmentos de texto directamente, se pueden resumir previamente o mencionar documentos y fuentes específicos asumiendo un conocimiento implícito por parte del modelo, y luego plantear preguntas o solicitudes basadas en esa información.

#### Consideraciones Importantes:

![img_1.png](ims%2FC5%2Fimg_1.png)

- **Eficiencia vs. Exactitud**: Es necesario encontrar un equilibrio entre la eficiencia del mensaje, lograda mediante la compresión y simplificación, y la exactitud de las respuestas generadas por el modelo. La omisión de información crucial puede llevar a respuestas incompletas o incorrectas.

- **Privacidad y Seguridad**: Al introducir datos o información en el modelo, es crucial considerar la confidencialidad y la seguridad de estos datos, especialmente al utilizar modelos hospedados en entornos compartidos o públicos.

- **Interacción Iterativa**: Dado el límite de tamaño en las entradas, puede ser útil adoptar un enfoque iterativo donde se exploran aspectos del problema en múltiples intercambios con el modelo, cada uno centrado en segmentos de la información relevante.

La capacidad de estructurar preguntas, solicitudes e información de manera estratégica no solo se adapta a las limitaciones técnicas de los modelos de lenguaje grandes sino que también promueve una interacción más rica, enfocada y productiva con estas avanzadas herramientas de IA.

### Prompts are a Tool for Repeated Use
[<- Return to INDEX 5](#index-5)

La interacción con modelos de lenguaje grandes, como ChatGPT, trasciende el simple intercambio de preguntas y respuestas. Adoptar un enfoque conversacional, contemplando el diálogo como un proceso iterativo y dinámico, permite un refinamiento progresivo de la comprensión y de las soluciones generadas por el modelo. Este método refleja cómo las conversaciones humanas se utilizan para explorar, clarificar y resolver problemas complejos a través de un intercambio interactivo de ideas.

#### Concepto Clave: Refinamiento Iterativo en la Comunicación

- **Proceso de Afinamiento**: Similar al método escultórico de Miguel Ángel, la interacción con el modelo no debe verse como un acto único que busca la perfección inmediata, sino como un proceso de refinamiento donde cada golpe es un paso más hacia la forma deseada.

- **Adaptabilidad**:
   - La convergencia hacia la solución óptima o el entendimiento deseado es más efectiva mediante ajustes iterativos basados en la retroalimentación recibida del modelo después de cada interacción.
   - Tal como un escultor evalúa y ajusta su técnica después de cada golpe al cincel, el usuario puede adaptar sus indicaciones basándose en las respuestas para guiar al modelo más eficazmente hacia el resultado deseado.

#### Ejemplo de Aplicación: Diseño de un Robot



- **Inicio de la Conversación**: Presentar el contexto general y el objetivo final (p. ej., diseñar un robot en un laboratorio virtual) establece los cimientos sobre los que se construirán interacciones subsecuentes.

    ![img_2.png](ims%2FC5%2Fimg_2.png)

- **Diálogo Progresivo**: La especificación gradual de detalles (meta del robot, materiales necesarios, funcionamiento deseado), alimentada por la retroalimentación del modelo, permite estructurar un plan de acción claro y detallado.

    ![img_3.png](ims%2FC5%2Fimg_3.png)

- **Resolución Colaborativa de Problemas**:

    ![img_4.png](ims%2FC5%2Fimg_4.png)   

   - Al enfrentarse a desafíos o limitaciones (como la dificultad de compartir modelos 3D a través del chat), la conversación puede adaptarse explorando alternativas viables (p.ej., uso de códigos G o STL para impresión 3D).
   - La colaboración virtual sugiere la posibilidad de adaptar la forma de trabajo a los límites del canal de comunicación, buscando siempre maneras creativas de sortear obstáculos.

#### Reflexiones y Estrategias:

- **Proceso Adaptativo**: Pensar en las interacciones con el modelo como parte de un flujo de trabajo adaptativo y no como eventos discretos aislados.

- **Interacción Basada en Objetivos**: Mantener el enfoque en el objetivo final para guiar el proceso de interacción hacia resultados constructivos y prácticos.

- **Uso de Retroalimentación**:
   - Integrar activamente la retroalimentación recibida en nuevas indicaciones, ajustando la dirección y el enfoque de la conversación según sea necesario.
   - Reconocer los límites del modelo y adaptar las expectativas y solicitudes en consecuencia para maximizar la utilidad de las respuestas generadas.

Adoptar un enfoque conversacional en la interacción con modelos de lenguaje grandes no solo amplía la gama de problemas que estos sistemas pueden ayudar a resolver sino que también enriquece la calidad y relevancia de las soluciones generadas, fomentando un diálogo productivo y creativo. Esta metodología refleja la importancia de la iteración y adaptabilidad como pilares de la exploración intelectual y la resolución de problemas en la era de la inteligencia artificial.

### Root Prompts
[<- Return to INDEX 5](#index-5)

Las instrucciones raíz en los modelos de lenguaje grandes como ChatGPT representan un conjunto fundamental de directrices que definen la conducta y las capacidades del modelo durante la interacción con los usuarios. Estas instrucciones, aunque no siempre son visibles para el usuario final, establecen parámetros esenciales que influyen en las respuestas generadas por la inteligencia artificial. La exploración y modificación de estas instrucciones raíz pueden abrir nuevas vías para personalizar la experiencia del usuario, establecer límites de seguridad y direccionar el modelo hacia objetivos específicos.

#### Importancia de las Instrucciones Raíz

![img_5.png](ims%2FC5%2Fimg_5.png)

- **Seguridad y Conformidad**: Aseguran que el modelo evite generar respuestas dañinas, inapropiadas o que transgredan los criterios éticos y normativos establecidos. Esto es crucial en un entorno donde los modelos de IA interactúan con una amplia gama de usuarios y contextos aplicativos.

- **Personalización**: Permiten adaptar el comportamiento del modelo para satisfacer necesidades específicas, como priorizar la eficiencia en el tiempo en recomendaciones, ajustándose así mejor al contexto y a las expectativas del usuario.

- **Limitación del Conocimiento**: Mediante instrucciones raíz se puede configurar el modelo para que reconozca sus límites cronológicos de entrenamiento, como ignorar eventos o información posterior a su última actualización, garantizando respuestas acordes a su base de conocimiento.

![img_6.png](ims%2FC5%2Fimg_6.png)

#### Modificación y Experimentación

La modificación de las instrucciones raíz abre experimentaciones interesantes, como:

![img_7.png](ims%2FC5%2Fimg_7.png)

- **Simulación de Limitaciones Temporales**: Ajustando "artificialmente" la fecha de corte del conocimiento del modelo y observar cómo influye en sus respuestas a ciertas preguntas o situaciones.
  
- **Creación de Roles Específicos**: Configurar el modelo para que actúe bajo ciertas "personalidades" o funciones, como un asistente personal especializado en eficiencia, puede brindar experiencias únicas y enfocadas.

#### Desafíos y Consideraciones

![img_8.png](ims%2FC5%2Fimg_8.png)

- **Integridad del Modelo**: Ajustar las instrucciones raíz sin contravenir las directrices éticas y de calidad impuestas por los desarrolladores del modelo es fundamental para mantener la responsabilidad y la utilidad del sistema.

- **Barandas Virtuales**: Establecer "barandas" efectivas que permitan explorar la flexibilidad del modelo sin traspasar los límites de seguridad, exactitud y adecuación.

- **Iteración y Refinamiento**: Como con cualquier proceso de modelado o programación, la creación de una experiencia personalizada mediante instrucciones raíz requiere iteración y refinamiento continuos para perfeccionar la interacción y alcanzar los objetivos deseados efectivamente.

La habilidad para ajustar las instrucciones raíz en modelos de lenguaje grandes representa una oportunidad emocionante y poderosa para personalizar la inteligencia artificial, asegurando al mismo tiempo que su aplicación sea segura, ética y efectivamente alineada con las intenciones del usuario. Esto subraya la evolución hacia sistemas de IA cada vez más sofisticados y adaptativos, capaces de ofrecer experiencias profundamente personalizadas y valiosas insights acorde a las necesidades específicas de cada usuario.

### Creating Prompts with New Information
[<- Return to INDEX 5](#index-5)

> Question 1
Create a prompt and test it with a large language model, such as ChatGPT, that introduces new information since 2021. Please only use public information. Do NOT use information that is private, subject to legal restrictions, or otherwise should not be shared with Coursera, ChatGPT, the instructor, etc. The prompt should require the large language model to answer a question about the information. Please provide your prompt and the output as the answer.
> 

Prompt: Do you know the Chabelo's death cause?

GPT: As of my last update in January 2022, Chabelo, whose real name is Xavier López Rodríguez, was alive. Therefore, I cannot provide information about his cause of death because it hadn't occurred by that time. If there have been any developments since then, I wouldn't be aware of them.

Prompt: Children’s comic and television icon Xavier López, better known as the TV personality “Chabelo,” has died due to “abdominal complications.” He was 88.

Best known for his TV show “En Familia con Chabelo,” which ran for 48 years from 1967 to 2015, López’s death was announced on his official Twitter page this morning with the following statement: “This is a very sad morning, Xavier López, Chabelo, father, brother and husband has left us suddenly, due to abdominal complications.”

The tweet was then followed by a statement from López’s family, “With a torn soul and knowing that many and many people have loved him for many years and that they will feel his departure, we ask you to pray for his rest and give us the opportunity to spend in peace the mourning that overwhelms our entire family.”

Host of Mexico’s longest-running TV show, López oversaw seven decades of children’s programming. The actor also starred in around 30 films and worked on countless additional TV shows.

President of Mexico, Andrés Manuel López Obrador expressed his condolences over the nation’s loss. “Hugs to family and friends for the death of Xavier López ‘Chabelo.’ How can I forget that my eldest son woke up early to see him over 40 years ago.”

Born in Chicago to Mexican parents, at a young age López and his parents returned back to Mexico. López trained as a doctor before his career as a comedic actor, which he believed was his true calling.

Throughout his career and well into his later years, López would dress and perform in children’s clothing which would grow into a treasured comic cornerstone throughout the Mexican cinematic landscape.

He is survived by his children and his wife, Teresita Miranda.

GPT:
Thank you for providing the update. It's indeed sad news to hear about the passing of Xavier López, known affectionately as Chabelo. His contributions to Mexican television and entertainment have left a lasting impact on generations of viewers. His long-running show, "En Familia con Chabelo," was a cherished part of many people's childhoods. López's ability to connect with audiences, his humor, and his dedication to children's programming will be remembered fondly. May he rest in peace, and may his family find comfort during this difficult time.

> Create a prompt and test it with a large language model, such as ChatGPT, that introduces new information since 2021. Please only use public information. Do NOT use information that is private, subject to legal restrictions, or otherwise should not be shared with Coursera, ChatGPT, the instructor, etc. The prompt should require the large language model to perform a task, other than answering a question, with the information. Please provide your prompt and the output as the answer.

Prompt: What's new in Python 3.12?

GPT:
As of my last update in January 2022, I don't have specific information on Python 3.12 since it hasn't been released yet. Python's development typically follows a cadence of releasing a new version every 18-24 months. Python's development process is transparent, so you can track the progress of new features, enhancements, and changes by following the Python Enhancement Proposals (PEPs) and the Python dev mailing list.

Prompt: I'll give you information about Python 3.12; with this information, can you provide me a simple Python Code that uses at least 2 new things?

This article explains the new features in Python 3.12, compared to 3.11. Python 3.12 was released on October 2, 2023. For full details, see the changelog.

See also PEP 693 – Python 3.12 Release Schedule
Summary – Release highlights
Python 3.12 is the latest stable release of the Python programming language, with a mix of changes to the language and the standard library. The library changes focus on cleaning up deprecated APIs, usability, and correctness. Of note, the distutils package has been removed from the standard library. Filesystem support in os and pathlib has seen a number of improvements, and several modules have better performance.

The language changes focus on usability, as f-strings have had many limitations removed and ‘Did you mean …’ suggestions continue to improve. The new type parameter syntax and type statement improve ergonomics for using generic types and type aliases with static type checkers.

This article doesn’t attempt to provide a complete specification of all new features, but instead gives a convenient overview. For full details, you should refer to the documentation, such as the Library Reference and Language Reference. If you want to understand the complete implementation and design rationale for a change, refer to the PEP for a particular new feature; but note that PEPs usually are not kept up-to-date once a feature has been fully implemented.

New syntax features:

PEP 695, type parameter syntax and the type statement

New grammar features:

PEP 701, f-strings in the grammar

Interpreter improvements:

PEP 684, a unique per-interpreter GIL

PEP 669, low impact monitoring

Improved ‘Did you mean …’ suggestions for NameError, ImportError, and SyntaxError exceptions

Python data model improvements:

PEP 688, using the buffer protocol from Python

Significant improvements in the standard library:

The pathlib.Path class now supports subclassing

The os module received several improvements for Windows support

A command-line interface has been added to the sqlite3 module

isinstance() checks against runtime-checkable protocols enjoy a speed up of between two and 20 times

The asyncio package has had a number of performance improvements, with some benchmarks showing a 75% speed up.

A command-line interface has been added to the uuid module

Due to the changes in PEP 701, producing tokens via the tokenize module is up to 64% faster.

Security improvements:

Replace the builtin hashlib implementations of SHA1, SHA3, SHA2-384, SHA2-512, and MD5 with formally verified code from the HACL* project. These builtin implementations remain as fallbacks that are only used when OpenSSL does not provide them.

C API improvements:

PEP 697, unstable C API tier

PEP 683, immortal objects

CPython implementation improvements:

PEP 709, comprehension inlining

CPython support for the Linux perf profiler

Implement stack overflow protection on supported platforms

New typing features:

PEP 692, using TypedDict to annotate **kwargs

PEP 698, typing.override() decorator

Important deprecations, removals or restrictions:

PEP 623: Remove wstr from Unicode objects in Python’s C API, reducing the size of every str object by at least 8 bytes.

PEP 632: Remove the distutils package. See the migration guide for advice replacing the APIs it provided. The third-party Setuptools package continues to provide distutils, if you still require it in Python 3.12 and beyond.

gh-95299: Do not pre-install setuptools in virtual environments created with venv. This means that distutils, setuptools, pkg_resources, and easy_install will no longer available by default; to access these run pip install setuptools in the activated virtual environment.

The asynchat, asyncore, and imp modules have been removed, along with several unittest.TestCase method aliases.

New Features
PEP 695: Type Parameter Syntax
Generic classes and functions under PEP 484 were declared using a verbose syntax that left the scope of type parameters unclear and required explicit declarations of variance.

PEP 695 introduces a new, more compact and explicit way to create generic classes and functions:

def max[T](args: Iterable[T]) -> T:
...

class list[T]:
def __getitem__(self, index: int, /) -> T:
...

def append(self, element: T) -> None:
...
In addition, the PEP introduces a new way to declare type aliases using the type statement, which creates an instance of TypeAliasType:

type Point = tuple[float, float]
Type aliases can also be generic:

type Point[T] = tuple[T, T]
The new syntax allows declaring TypeVarTuple and ParamSpec parameters, as well as TypeVar parameters with bounds or constraints:

type IntFunc[**P] = Callable[P, int] # ParamSpec
type LabeledTuple[*Ts] = tuple[str, *Ts] # TypeVarTuple
type HashableSequence[T: Hashable] = Sequence[T] # TypeVar with bound
type IntOrStrSequence[T: (int, str)] = Sequence[T] # TypeVar with constraints
The value of type aliases and the bound and constraints of type variables created through this syntax are evaluated only on demand (see lazy evaluation). This means type aliases are able to refer to other types defined later in the file.

Type parameters declared through a type parameter list are visible within the scope of the declaration and any nested scopes, but not in the outer scope. For example, they can be used in the type annotations for the methods of a generic class or in the class body. However, they cannot be used in the module scope after the class is defined. See Type parameter lists for a detailed description of the runtime semantics of type parameters.

In order to support these scoping semantics, a new kind of scope is introduced, the annotation scope. Annotation scopes behave for the most part like function scopes, but interact differently with enclosing class scopes. In Python 3.13, annotations will also be evaluated in annotation scopes.

See PEP 695 for more details.


GPT: Here's a simple Python code that uses two new features introduced in Python 3.12:

Type parameter syntax and the type statement (PEP 695)
Syntactic formalization of f-strings (PEP 701)
python
Copy code
from typing import TypeVar, Iterable

Define a type variable T
T = TypeVar('T')

Define a generic function using type parameter syntax

def max_item(items: Iterable[T]) -> T:
max_val = None
for item in items:
if max_val is None or item > max_val:
max_val = item
return max_val

Example usage

numbers = [1, 5, 3, 9, 2]
max_number = max_item(numbers)
print(f"The maximum number is: {max_number}")

words = ["apple", "banana", "orange"]
max_word = max_item(words)
print(f"The maximum word is: {max_word}")
In this code:

We define a type variable T using the TypeVar function.
We define a generic function max_item using the new type parameter syntax introduced in PEP 695. This function can accept any iterable of a generic type T and returns the maximum value from the iterable.
We use this generic function to find the maximum number from a list of numbers and the maximum word from a list of strings.
We use the new syntactic formalization of f-strings introduced in PEP 701 to print out the results.

### What to Take After or With this Course
[<- Return to INDEX 5](#index-5)

Acaba de empezar este curso, pero quiero informarle sobre otro curso que puede realizar simultáneamente o después de este curso para sacar aún más partido a ChatGPT. 

Si tiene una suscripción a ChatGPT+, mi curso sobre Análisis Avanzado de Datos de 
ChatGPT
 es un gran paso siguiente. El Análisis Avanzado de Datos de [ChatGPT](https://www.coursera.org/learn/chatgpt-advanced-data-analysis) es una herramienta transformadora para utilizar ChatGPT en el trabajo y con documentos reales. 

El Análisis Avanzado de Datos es como una pala que mira hacia donde está a punto de cavar, se da cuenta de que hay una roca en el camino, salta de sus manos y construye un pico, lo utiliza para romper la roca, y luego salta de nuevo a sus manos para que pueda seguir cavando.

Algunos ejemplos de cosas que aprenderá a hacer en mi nuevo curso:

1. Hacer que el intérprete de código lea sus diapositivas de PowerPoint o sus documentos y cuestione sus suposiciones y le haga preguntas difíciles.

2. Visualice y analice datos de Excel o extraídos directamente de PDF y, a continuación, convierta las visualizaciones en PowerPoint u otros documentos.

3. Automatice operaciones sobre soportes, como redimensionar imágenes, aplicar filtros y catalogarlo todo en un archivo CSV.

4. Comprima un montón de PDF y deje que Code Interpreter lea y reorganice los archivos por usted y luego le entregue un archivo Zip con la nueva estructura de directorios y nomenclatura.

5. Cargue un PDF de un documento de política y haga que responda a preguntas sobre la política o que aplique la política (por ejemplo, aplicar una política de viajes a un recibo para determinar si es reembolsable).

https://www.coursera.org/learn/chatgpt-advanced-data-analysis

## Introduction to Prompt Patterns
[<- Return to INDEX 0](#index-0)

### INDEX 6

- [Question Refinement Pattern](#question-refinement-pattern)
- [Format of the Question Refinement Pattern](#format-of-the-question-refinement-pattern)
- [Cognitive Verifier Pattern](#cognitive-verifier-pattern)
- [Format of the Cognitive Verifier Pattern](#format-of-the-cognitive-verifier-pattern)
- [Audience Persona Pattern](#audience-persona-pattern)
- [Format of the Audience Persona Pattern](#format-of-the-audience-persona-pattern)
- [Flipped Interaction Pattern](#flipped-interaction-pattern)
- [Format of the Flipped Interaction Pattern](#format-of-the-flipped-interaction-pattern)
- [Applying Prompt Patterns I](#applying-prompt-patterns-i)

### Question Refinement Pattern
[<- Return to INDEX 6](#index-6)

### Format of the Question Refinement Pattern
[<- Return to INDEX 6](#index-6)

### Cognitive Verifier Pattern
[<- Return to INDEX 6](#index-6)

### Format of the Cognitive Verifier Pattern
[<- Return to INDEX 6](#index-6)

### Audience Persona Pattern
[<- Return to INDEX 6](#index-6)

### Format of the Audience Persona Pattern
[<- Return to INDEX 6](#index-6)

### Flipped Interaction Pattern
[<- Return to INDEX 6](#index-6)

### Format of the Flipped Interaction Pattern
[<- Return to INDEX 6](#index-6)

### Applying Prompt Patterns I
[<- Return to INDEX 6](#index-6)

## Effective Prompts
[<- Return to INDEX 0](#index-0)

### INDEX 7

- [Few-shot Examples](#few-shot-examples)
- [Few-shot Examples for Actions](#few-shot-examples-for-actions)
- [Few-Shot Examples with Intermediate Steps](#few-shot-examples-with-intermediate-steps)
- [Writing Effective Few-Shot Examples](#writing-effective-few-shot-examples)
- [Chain of Thought Prompting](#chain-of-thought-prompting)
- [Learn More About Chain of Thought Prompting](#learn-more-about-chain-of-thought-prompting)
- [ReAct Prompting](#react-prompting)
- [Learn More About ReAct](#learn-more-about-react)
- [Using Large Language Models to Grade Each Other](#using-large-language-models-to-grade-each-other)
- [Applying Few-Shot Examples Concepts](#applying-few-shot-examples-concepts)

### Few-shot Examples
[<- Return to INDEX 7](#index-7)

### Few-shot Examples for Actions
[<- Return to INDEX 7](#index-7)

### Few-Shot Examples with Intermediate Steps
[<- Return to INDEX 7](#index-7)

### Writing Effective Few-Shot Examples
[<- Return to INDEX 7](#index-7)

### Chain of Thought Prompting
[<- Return to INDEX 7](#index-7)

### Learn More About Chain of Thought Prompting
[<- Return to INDEX 7](#index-7)

### ReAct Prompting
[<- Return to INDEX 7](#index-7)

### Learn More About ReAct
[<- Return to INDEX 7](#index-7)

### Using Large Language Models to Grade Each Other
[<- Return to INDEX 7](#index-7)

### Applying Few-Shot Examples Concepts
[<- Return to INDEX 7](#index-7)

## Prompt Patterns Catalog 1
[<- Return to INDEX 0](#index-0)

### INDEX 8

- [Game Play Pattern](#game-play-pattern)
- [Format of the Game Play Pattern](#format-of-the-game-play-pattern)
- [Template Pattern](#template-pattern)
- [Format of the Template Pattern](#format-of-the-template-pattern)
- [Meta Language Creation Pattern](#meta-language-creation-pattern)
- [Format of the Meta Language Creation Pattern](#format-of-the-meta-language-creation-pattern)
- [Recipe Pattern](#recipe-pattern)
- [Format of the Recipe Pattern](#format-of-the-recipe-pattern)
- [Alternative Approaches Pattern](#alternative-approaches-pattern)
- [Format of the Alternative Approaches Pattern](#format-of-the-alternative-approaches-pattern)
- [Applying Prompt Patterns II](#applying-prompt-patterns-ii)

### Game Play Pattern
[<- Return to INDEX 8](#index-8)

### Format of the Game Play Pattern
[<- Return to INDEX 8](#index-8)

### Template Pattern
[<- Return to INDEX 8](#index-8)

### Format of the Template Pattern
[<- Return to INDEX 8](#index-8)

### Meta Language Creation Pattern
[<- Return to INDEX 8](#index-8)

### Format of the Meta Language Creation Pattern
[<- Return to INDEX 8](#index-8)

### Recipe Pattern
[<- Return to INDEX 8](#index-8)

### Format of the Recipe Pattern
[<- Return to INDEX 8](#index-8)

### Alternative Approaches Pattern
[<- Return to INDEX 8](#index-8)

### Format of the Alternative Approaches Pattern
[<- Return to INDEX 8](#index-8)

### Applying Prompt Patterns II
[<- Return to INDEX 8](#index-8)

## Prompt Patterns Catalog 2
[<- Return to INDEX 0](#index-0)

### INDEX 9

- [Ask for Input Pattern](#ask-for-input-pattern)
- [Format of the Ask for Input Pattern](#format-of-the-ask-for-input-pattern)
- [Combining Patterns](#combining-patterns)
- [Outline Expansion Pattern](#outline-expansion-pattern)
- [Format of the Outline Expansion Pattern](#format-of-the-outline-expansion-pattern)
- [Menu Actions Pattern](#menu-actions-pattern)
- [Format of the Menu Actions Pattern](#format-of-the-menu-actions-pattern)
- [Fact Check List Pattern](#fact-check-list-pattern)
- [Format of the Fact Check List Pattern](#format-of-the-fact-check-list-pattern)
- [Tail Generation Pattern](#tail-generation-pattern)
- [Semantic Filter Pattern](#semantic-filter-pattern)
- [Format of the Semantic Filter Pattern](#format-of-the-semantic-filter-pattern)
- [Course Conclusion & Thank You](#course-conclusion--thank-you)
- [Continue Learning About Prompt Engineering](#continue-learning-about-prompt-engineering)
- [Creating a Prompt-based Application](#creating-a-prompt-based-application)

### Ask for Input Pattern
[<- Return to INDEX 9](#index-9)

### Format of the Ask for Input Pattern
[<- Return to INDEX 9](#index-9)

### Combining Patterns
[<- Return to INDEX 9](#index-9)

### Outline Expansion Pattern
[<- Return to INDEX 9](#index-9)

### Format of the Outline Expansion Pattern
[<- Return to INDEX 9](#index-9)

### Menu Actions Pattern
[<- Return to INDEX 9](#index-9)

### Format of the Menu Actions Pattern
[<- Return to INDEX 9](#index-9)

### Fact Check List Pattern
[<- Return to INDEX 9](#index-9)

### Format of the Fact Check List Pattern
[<- Return to INDEX 9](#index-9)

### Tail Generation Pattern
[<- Return to INDEX 9](#index-9)

### Semantic Filter Pattern
[<- Return to INDEX 9](#index-9)

### Format of the Semantic Filter Pattern
[<- Return to INDEX 9](#index-9)

### Course Conclusion & Thank You
[<- Return to INDEX 9](#index-9)

### Continue Learning About Prompt Engineering
[<- Return to INDEX 9](#index-9)

### Creating a Prompt-based Application
[<- Return to INDEX 9](#index-9)